# 30-days-of-ML

# Day-1

This notebook demonstrates basic **NumPy** operations using Python, ideal for beginners in data science or machine learning.

## ğŸ“˜ Overview

- Creating NumPy arrays
- Element-wise array operations: addition, subtraction, multiplication, and division
- Scalar operations on arrays
- Built-in NumPy functions: `sum`, `mean`, `std`, etc.
- Simple data import with Pandas (Excel/CSV)

## ğŸ”§ Features

- Learn vectorized operations with NumPy arrays
- Perform arithmetic and statistical operations
- Understand broadcasting and scalar manipulation
- Read a dataset using Pandas (example: COVID-19 dataset)

## ğŸ› ï¸ Technologies Used

- Python
- NumPy
- Pandas
- Jupyter Notebook

## ğŸš€ How to Use
  [Code Link](https://github.com/krishchapla/30-days-of-ML/blob/main/Day1.ipynb)




  # ğŸ“Š Day 2 - Data Preprocessing & Exploration (30 Days of ML)

This notebook marks **Day 2** of my 30 Days of Machine Learning journey. The focus is on data preprocessing and basic exploratory data analysis (EDA) using Pandas and NumPy.

## ğŸ§  Key Concepts Covered

- Reading data from Excel using `pandas.read_excel()`
- Inspecting datasets (`head()`, `info()`, `describe()`)
- Handling missing values
- Basic statistical analysis
- Column operations and data filtering

## ğŸ› ï¸ Tools Used

- Python
- Jupyter Notebook
- Pandas
- NumPy
- Matplotlib 

## ğŸš€ How to Use
  [Code Link](https://github.com/krishchapla/30-days-of-ML/blob/main/Day2.ipynb)



  # ğŸ“ˆ Day 3 â€“ Regression & Classification Models (30 Days of ML)

Day 3 of my Machine Learning journey focuses on implementing **Linear Regression** and **Logistic Regression** using real-world COVID-19 data in India.

## ğŸ§  What This Notebook Covers

### ğŸ”¹ Linear Regression
- Predicting **Recovered Cases** based on **Total Confirmed Cases**
- Train-test split for evaluation
- Visualization of regression line
- Model evaluation using **Mean Squared Error**

### ğŸ”¹ Logistic Regression
- Classifying **High Risk** regions based on **Deaths**
- Thresholding TotalConfirmedCases to create binary labels
- Model evaluation using **Accuracy** and **Classification Report**
- Visualization of predictions

## ğŸ› ï¸ Tools & Libraries
- Python  
- NumPy & Pandas  
- Matplotlib  
- Scikit-learn (LinearRegression, LogisticRegression)

## ğŸš€ How to Run

 [Code Link](https://github.com/krishchapla/30-days-of-ML/blob/main/Day3.ipynb)


Day 4 â€“ 30 Days of ML ğŸš€
Topic: Data Preprocessing & Feature Engineering
ğŸ“Œ What I learned:
Handling missing values using dropna()

One-hot encoding for categorical features

Feature scaling using StandardScaler

Splitting dataset into training and test sets with train_test_split

ğŸ› ï¸ Libraries Used:
pandas

numpy

scikit-learn

ğŸ“Š Dataset:
COVID-19 dataset (India)

ğŸ” Workflow Summary:
Dropped null values

Converted categorical data using one-hot encoding

Scaled features to normalize data

Prepared data for modeling by splitting into train/test sets

## ğŸš€ How to Run

 [Code Link](https://github.com/krishchapla/30-days-of-ML/blob/main/Day4.ipynb)

# ğŸ“Š Day 5 - Market Analysis & Data Preprocessing

This notebook demonstrates data cleaning and preprocessing on a real-world **market analysis dataset**. It focuses on preparing data for future machine learning tasks.

## âœ… Key Concepts Covered

- Loaded Excel dataset using `pandas.read_excel()`
- Identified and filled missing values using **mean imputation**
- Applied **One-Hot Encoding** for categorical columns
- Performed **feature scaling** with `StandardScaler`

## ğŸ› ï¸ Libraries Used

- Python
- Pandas
- NumPy
- Scikit-learn

## ğŸš€ How to Run

 [Code Link](https://github.com/krishchapla/30-days-of-ML/blob/main/Day5.ipynb)





